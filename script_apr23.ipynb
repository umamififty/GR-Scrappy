{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739d9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb5db866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GovUKPolicyScraper:\n",
    "    def __init__(self, base_dir=\"policy_data\"):\n",
    "        \"\"\"\n",
    "        Initialize the scraper\n",
    "        \n",
    "        Args:\n",
    "            base_dir (str): Base directory to store all downloaded data\n",
    "        \"\"\"\n",
    "        self.base_url = \"https://www.gov.uk\"\n",
    "        self.base_dir = base_dir\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'PolicyResearch/1.0 (Academic Research)'\n",
    "        })\n",
    "        \n",
    "        # Create base directory\n",
    "        os.makedirs(self.base_dir, exist_ok=True)\n",
    "    \n",
    "    def search_policies(self, search_term=None, page_limit=5, exclude_types=None):\n",
    "        \"\"\"\n",
    "        Search for policy papers on gov.uk\n",
    "        \n",
    "        Args:\n",
    "            search_term (str): Optional keyword to search for\n",
    "            page_limit (int): Maximum number of pages to scrape\n",
    "            exclude_types (list): Types of documents to exclude, e.g. ['consultations']\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing search results\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        # Use only policy-papers, not consultations\n",
    "        search_url = f\"{self.base_url}/search/policy-papers-and-consultations\"\n",
    "        \n",
    "        params = {\n",
    "            'keywords': search_term if search_term else '',\n",
    "            'content_store_document_type': 'policy_papers'\n",
    "        }\n",
    "        \n",
    "        print(f\"Starting full extraction process for all policy papers\")\n",
    "        print(f\"Scraping all policy papers (up to {page_limit} pages)\")\n",
    "        \n",
    "        for page in range(1, page_limit + 1):\n",
    "            params['page'] = page\n",
    "            try:\n",
    "                print(f\"Scraping page {page}...\")\n",
    "                response = self.session.get(search_url, params=params)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                results_container = soup.find('div', id='js-results')\n",
    "                \n",
    "                if not results_container:\n",
    "                    print(f\"Could not find results container with id 'js-results' on page {page}\")\n",
    "                    continue\n",
    "                    \n",
    "                results_list = results_container.find_all('li', class_='gem-c-document-list__item')\n",
    "                \n",
    "                if not results_list:\n",
    "                    print(f\"No results found on page {page}, stopping pagination\")\n",
    "                    break\n",
    "                \n",
    "                print(f\"Found {len(results_list)} results on page {page}\")\n",
    "                \n",
    "                page_results = []\n",
    "                for item in results_list:\n",
    "                    # Skip consultations if in exclude_types\n",
    "                    if exclude_types and any(excluded in item.text.lower() for excluded in exclude_types):\n",
    "                        continue\n",
    "                        \n",
    "                    policy_data = self._extract_policy_data(item)\n",
    "                    if policy_data:\n",
    "                        # Extract categories\n",
    "                        policy_url = policy_data['url']\n",
    "                        categories = self._extract_categories(policy_url)\n",
    "                        policy_data.update(categories)\n",
    "                        \n",
    "                        page_results.append(policy_data)\n",
    "                        print(f\"Extracted: {policy_data['title']}\")\n",
    "                \n",
    "                all_results.extend(page_results)\n",
    "                print(f\"Total results so far: {len(all_results)}\")\n",
    "                \n",
    "                # Add a small delay to be respectful to the server\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error fetching page {page}: {e}\")\n",
    "                break\n",
    "        \n",
    "        policies_df = pd.DataFrame(all_results)\n",
    "        print(f\"Found {len(policies_df)} policies\")\n",
    "        \n",
    "        # Save the policies data\n",
    "        if not policies_df.empty:\n",
    "            csv_path = os.path.join(self.base_dir, \"all_policies.csv\")\n",
    "            policies_df.to_csv(csv_path, index=False)\n",
    "            print(f\"Saved policies data to {csv_path}\")\n",
    "        \n",
    "        return policies_df\n",
    "    \n",
    "    # def _extract_policy_data(self, item):\n",
    "    #     \"\"\"\n",
    "    #     Extract policy data from a search result item\n",
    "        \n",
    "    #     Args:\n",
    "    #         item: BeautifulSoup object for a search result\n",
    "            \n",
    "    #     Returns:\n",
    "    #         dict: Dictionary with policy data\n",
    "    #     \"\"\"\n",
    "    #     try:\n",
    "    #         title_tag = item.find('a', class_='gem-c-document-list__item-title')\n",
    "    #         if not title_tag:\n",
    "    #             # Try alternative selector\n",
    "    #             title_tag = item.select_one('div.gem-c-document-list__item-title a')\n",
    "    #             if not title_tag:\n",
    "    #                 return None\n",
    "                    \n",
    "    #         title = title_tag.text.strip()\n",
    "    #         link = title_tag.get('href')\n",
    "    #         full_link = self.base_url + link if link.startswith('/') else link\n",
    "            \n",
    "    #         # Extract metadata\n",
    "    #         metadata_container = item.find('ul', class_='gem-c-document-list__item-metadata')\n",
    "    #         metadata = {\n",
    "    #             'published_date': None,\n",
    "    #             'department': None,\n",
    "    #             'type': None\n",
    "    #         }\n",
    "            \n",
    "    #         if metadata_container:\n",
    "    #             metadata_items = metadata_container.find_all('li')\n",
    "    #             for meta_item in metadata_items:\n",
    "    #                 text = meta_item.text.strip()\n",
    "    #                 if \"Published\" in text:\n",
    "    #                     metadata['published_date'] = text.replace(\"Published: \", \"\")\n",
    "    #                 elif \"Organisation\" in text or \"Department\" in text or \"From\" in text:\n",
    "    #                     metadata['department'] = text.replace(\"Organisation: \", \"\").replace(\"Department: \", \"\").replace(\"From: \", \"\")\n",
    "    #                 else:\n",
    "    #                     metadata['type'] = text\n",
    "            \n",
    "    #         # Extract description\n",
    "    #         description_tag = item.find('p', class_='gem-c-document-list__item-description')\n",
    "    #         description = description_tag.text.strip() if description_tag else None\n",
    "            \n",
    "    #         return {\n",
    "    #             'title': title,\n",
    "    #             'url': full_link,\n",
    "    #             'description': description,\n",
    "    #             **metadata\n",
    "    #         }\n",
    "            \n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error extracting policy data: {e}\")\n",
    "    #         return None\n",
    "\n",
    "    \n",
    "    def _extract_policy_data(self, item):\n",
    "        \"\"\"\n",
    "        Extract policy data from a search result item\n",
    "        \n",
    "        Args:\n",
    "            item: BeautifulSoup object for a search result\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary with policy data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            title_tag = item.find('a', class_='gem-c-document-list__item-title')\n",
    "            if not title_tag:\n",
    "                # Try alternative selector\n",
    "                title_tag = item.select_one('div.gem-c-document-list__item-title a')\n",
    "                if not title_tag:\n",
    "                    return None\n",
    "                    \n",
    "            title = title_tag.text.strip()\n",
    "            link = title_tag.get('href')\n",
    "            full_link = self.base_url + link if link.startswith('/') else link\n",
    "            \n",
    "            # Extract metadata\n",
    "            metadata_container = item.find('ul', class_='gem-c-document-list__item-metadata')\n",
    "            metadata = {\n",
    "                'published_date': None,\n",
    "                'updated_date': None,\n",
    "                'department': None,\n",
    "                'type': None\n",
    "            }\n",
    "            \n",
    "            if metadata_container:\n",
    "                metadata_items = metadata_container.find_all('li')\n",
    "                for meta_item in metadata_items:\n",
    "                    text = meta_item.text.strip()\n",
    "                    if \"Published\" in text:\n",
    "                        date_part = text.replace(\"Published: \", \"\").strip()\n",
    "                        metadata['published_date'] = date_part\n",
    "                    elif \"Organisation\" in text or \"Department\" in text or \"From\" in text:\n",
    "                        metadata['department'] = text.replace(\"Organisation: \", \"\").replace(\"Department: \", \"\").replace(\"From: \", \"\")\n",
    "                    else:\n",
    "                        metadata['type'] = text\n",
    "            \n",
    "            # If dates weren't found in the list metadata, try to get them from the policy page metadata\n",
    "            if (not metadata['published_date'] or not metadata['updated_date']) and full_link:\n",
    "                try:\n",
    "                    # Get the policy detail page\n",
    "                    response = self.session.get(full_link)\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    detail_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                    \n",
    "                    # Look for the published date in the head metadata\n",
    "                    published_meta = detail_soup.find('meta', attrs={'name': 'govuk:first-published-at'})\n",
    "                    if published_meta:\n",
    "                        published_date = published_meta.get('content')\n",
    "                        if published_date:\n",
    "                            # Convert ISO format to more readable format (optional)\n",
    "                            try:\n",
    "                                from datetime import datetime\n",
    "                                dt = datetime.fromisoformat(published_date.replace('Z', '+00:00'))\n",
    "                                metadata['published_date'] = dt.strftime('%d %B %Y')\n",
    "                            except Exception:\n",
    "                                # If date parsing fails, just use the original string\n",
    "                                metadata['published_date'] = published_date\n",
    "                    \n",
    "                    # Look for the updated date in the head metadata\n",
    "                    updated_meta = detail_soup.find('meta', attrs={'name': 'govuk:updated-at'})\n",
    "                    if updated_meta:\n",
    "                        updated_date = updated_meta.get('content')\n",
    "                        if updated_date:\n",
    "                            # Convert ISO format to more readable format (optional)\n",
    "                            try:\n",
    "                                from datetime import datetime\n",
    "                                dt = datetime.fromisoformat(updated_date.replace('Z', '+00:00'))\n",
    "                                metadata['updated_date'] = dt.strftime('%d %B %Y')\n",
    "                            except Exception:\n",
    "                                # If date parsing fails, just use the original string\n",
    "                                metadata['updated_date'] = updated_date\n",
    "                    \n",
    "                    # If still no published date, try the public web published date\n",
    "                    if not metadata['published_date']:\n",
    "                        public_meta = detail_soup.find('meta', attrs={'name': 'govuk:public-updated-at'})\n",
    "                        if public_meta:\n",
    "                            public_date = public_meta.get('content')\n",
    "                            if public_date:\n",
    "                                try:\n",
    "                                    from datetime import datetime\n",
    "                                    dt = datetime.fromisoformat(public_date.replace('Z', '+00:00'))\n",
    "                                    metadata['published_date'] = dt.strftime('%d %B %Y')\n",
    "                                except Exception:\n",
    "                                    metadata['published_date'] = public_date\n",
    "                    \n",
    "                    # Add a small delay to be respectful to the server\n",
    "                    time.sleep(1)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching policy page for date extraction: {e}\")\n",
    "            \n",
    "            # Extract description\n",
    "            description_tag = item.find('p', class_='gem-c-document-list__item-description')\n",
    "            description = description_tag.text.strip() if description_tag else None\n",
    "            \n",
    "            return {\n",
    "                'title': title,\n",
    "                'url': full_link,\n",
    "                'description': description,\n",
    "                **metadata\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting policy data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _extract_categories(self, url):\n",
    "        \"\"\"\n",
    "        Extract categories from a policy page\n",
    "        \n",
    "        Args:\n",
    "            url (str): URL of the policy page\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary with category information\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            categories = {\n",
    "                'category': None,\n",
    "                'subcategory': None\n",
    "            }\n",
    "            \n",
    "            # Try to find categories from breadcrumbs\n",
    "            breadcrumb = soup.find('nav', class_='govuk-breadcrumbs')\n",
    "            if breadcrumb:\n",
    "                breadcrumb_items = breadcrumb.find_all('li', class_='govuk-breadcrumbs__list-item')\n",
    "                \n",
    "                # Breadcrumb structure is typically: Home > Category > Subcategory\n",
    "                if len(breadcrumb_items) >= 2:\n",
    "                    # Skip \"Home\", get category\n",
    "                    category_item = breadcrumb_items[1]\n",
    "                    category_link = category_item.find('a')\n",
    "                    if category_link:\n",
    "                        categories['category'] = category_link.text.strip()\n",
    "                \n",
    "                # Get subcategory if available\n",
    "                if len(breadcrumb_items) >= 3:\n",
    "                    subcategory_item = breadcrumb_items[2]\n",
    "                    subcategory_link = subcategory_item.find('a')\n",
    "                    if subcategory_link:\n",
    "                        categories['subcategory'] = subcategory_link.text.strip()\n",
    "            \n",
    "            # If not found in breadcrumbs, try alternative methods\n",
    "            if not categories['category']:\n",
    "                # Look for topic tags\n",
    "                topic_tags = soup.find_all('a', class_=lambda c: c and 'topic' in (c or '').lower())\n",
    "                if topic_tags:\n",
    "                    categories['category'] = topic_tags[0].text.strip()\n",
    "            \n",
    "            return categories\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting categories: {e}\")\n",
    "            return {'category': None, 'subcategory': None}\n",
    "    \n",
    "    def download_policy_attachments(self, policies_df):\n",
    "        \"\"\"\n",
    "        Download and organize attachments from policies\n",
    "        \n",
    "        Args:\n",
    "            policies_df (pd.DataFrame): DataFrame with policy data\n",
    "            \n",
    "        Returns:\n",
    "            int: Number of attachments downloaded\n",
    "        \"\"\"\n",
    "        download_count = 0\n",
    "        \n",
    "        if policies_df.empty:\n",
    "            print(\"No policies to process\")\n",
    "            return download_count\n",
    "        \n",
    "        print(f\"Downloading attachments for {len(policies_df)} policies...\")\n",
    "        \n",
    "        for _, policy in policies_df.iterrows():\n",
    "            try:\n",
    "                title = policy['title']\n",
    "                url = policy['url']\n",
    "                category = policy.get('category', 'Uncategorized')\n",
    "                subcategory = policy.get('subcategory', 'General')\n",
    "                \n",
    "                print(f\"Processing: {title}\")\n",
    "                \n",
    "                # Create folder structure\n",
    "                category_dir = self._sanitize_filename(category)\n",
    "                subcategory_dir = self._sanitize_filename(subcategory)\n",
    "                policy_dir = self._sanitize_filename(title)\n",
    "                \n",
    "                full_path = os.path.join(self.base_dir, category_dir, subcategory_dir, policy_dir)\n",
    "                os.makedirs(full_path, exist_ok=True)\n",
    "                \n",
    "                # Get policy detail page\n",
    "                response = self.session.get(url)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                \n",
    "                # Find attachments\n",
    "                attachment_sections = soup.find_all(['div', 'section'], class_=lambda c: c and 'attachment' in c)\n",
    "                if not attachment_sections:\n",
    "                    print(f\"No attachments found for: {title}\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract and download attachments\n",
    "                policy_attachments = []\n",
    "                for section in attachment_sections:\n",
    "                    attachment_links = section.find_all('a')\n",
    "                    for link in attachment_links:\n",
    "                        href = link.get('href')\n",
    "                        if not href:\n",
    "                            continue\n",
    "                            \n",
    "                        # Only download document files\n",
    "                        if re.search(r'\\.(pdf|doc|docx|xls|xlsx|ppt|pptx|csv)$', href, re.I):\n",
    "                            attachment_url = urljoin(self.base_url, href)\n",
    "                            filename = os.path.basename(href)\n",
    "                            save_path = os.path.join(full_path, filename)\n",
    "                            \n",
    "                            # Download the file\n",
    "                            print(f\"Downloading: {filename}\")\n",
    "                            try:\n",
    "                                file_response = self.session.get(attachment_url, stream=True)\n",
    "                                file_response.raise_for_status()\n",
    "                                \n",
    "                                with open(save_path, 'wb') as f:\n",
    "                                    for chunk in file_response.iter_content(chunk_size=8192):\n",
    "                                        f.write(chunk)\n",
    "                                \n",
    "                                policy_attachments.append({\n",
    "                                    'filename': filename,\n",
    "                                    'url': attachment_url,\n",
    "                                    'path': save_path\n",
    "                                })\n",
    "                                \n",
    "                                download_count += 1\n",
    "                                print(f\"Saved to: {save_path}\")\n",
    "                                \n",
    "                                # Be nice to the server\n",
    "                                time.sleep(1)\n",
    "                                \n",
    "                            except Exception as e:\n",
    "                                print(f\"Error downloading {filename}: {e}\")\n",
    "                \n",
    "                # Create metadata file with policy information\n",
    "                metadata = {\n",
    "                    'title': title,\n",
    "                    'url': url,\n",
    "                    'published_date': policy.get('published_date'),\n",
    "                    'department': policy.get('department'),\n",
    "                    'category': category,\n",
    "                    'subcategory': subcategory,\n",
    "                    'description': policy.get('description'),\n",
    "                    'attachments': policy_attachments\n",
    "                }\n",
    "                \n",
    "                metadata_path = os.path.join(full_path, 'metadata.json')\n",
    "                import json\n",
    "                with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing policy {policy['title']}: {e}\")\n",
    "        \n",
    "        print(f\"Total attachments downloaded: {download_count}\")\n",
    "        return download_count\n",
    "    \n",
    "    def categorize_policies(self, policies_df):\n",
    "        \"\"\"\n",
    "        Organize policies by category and subcategory\n",
    "        \n",
    "        Args:\n",
    "            policies_df (pd.DataFrame): DataFrame with policy data\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary with categorized policies\n",
    "        \"\"\"\n",
    "        if policies_df.empty:\n",
    "            return {}\n",
    "        \n",
    "        # Initialize category structure\n",
    "        categories = {}\n",
    "        \n",
    "        # Group by category and subcategory\n",
    "        for _, policy in policies_df.iterrows():\n",
    "            category = policy.get('category', 'Uncategorized')\n",
    "            subcategory = policy.get('subcategory', 'General')\n",
    "            \n",
    "            if category not in categories:\n",
    "                categories[category] = {'subcategories': {}}\n",
    "            \n",
    "            if subcategory not in categories[category]['subcategories']:\n",
    "                categories[category]['subcategories'][subcategory] = {'policies': []}\n",
    "            \n",
    "            # Add policy to appropriate subcategory\n",
    "            categories[category]['subcategories'][subcategory]['policies'].append({\n",
    "                'title': policy['title'],\n",
    "                'url': policy['url'],\n",
    "                'published_date': policy.get('published_date'),\n",
    "                'department': policy.get('department')\n",
    "            })\n",
    "        \n",
    "        # Calculate counts\n",
    "        for category, cat_data in categories.items():\n",
    "            cat_policy_count = 0\n",
    "            \n",
    "            for subcategory, subcat_data in cat_data['subcategories'].items():\n",
    "                policies_count = len(subcat_data['policies'])\n",
    "                cat_data['subcategories'][subcategory]['count'] = policies_count\n",
    "                cat_policy_count += policies_count\n",
    "            \n",
    "            cat_data['count'] = cat_policy_count\n",
    "        \n",
    "        # Save category structure\n",
    "        import json\n",
    "        categories_path = os.path.join(self.base_dir, 'category_structure.json')\n",
    "        with open(categories_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(categories, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Category structure saved to {categories_path}\")\n",
    "        \n",
    "        # Print category summary\n",
    "        print(\"\\nCategory Summary:\")\n",
    "        print(\"=\" * 40)\n",
    "        for category, cat_data in categories.items():\n",
    "            print(f\"{category}: {cat_data['count']} policies\")\n",
    "            for subcategory, subcat_data in cat_data['subcategories'].items():\n",
    "                print(f\"  - {subcategory}: {subcat_data['count']} policies\")\n",
    "        \n",
    "        return categories\n",
    "    \n",
    "    def _sanitize_filename(self, name):\n",
    "        \"\"\"\n",
    "        Convert a string to a valid directory name\n",
    "        \n",
    "        Args:\n",
    "            name (str): String to sanitize\n",
    "            \n",
    "        Returns:\n",
    "            str: Sanitized string\n",
    "        \"\"\"\n",
    "        if not name:\n",
    "            return \"Unknown\"\n",
    "            \n",
    "        # Replace invalid characters\n",
    "        s = re.sub(r'[\\\\/*?:\"<>|]', '', name)\n",
    "        # Replace multiple spaces with a single space\n",
    "        s = re.sub(r'\\s+', ' ', s)\n",
    "        # Trim the name if it's too long\n",
    "        if len(s) > 75:\n",
    "            s = s[:75]\n",
    "        \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51aa1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting full extraction process for all policy papers\n",
      "Scraping all policy papers (up to 1 pages)\n",
      "Scraping page 1...\n",
      "Found 20 results on page 1\n",
      "Extracted: Crime and Policing Bill 2025: Delegated powers supplementary memoranda\n",
      "Extracted: Crime and Policing Bill 2025: ECHR supplementary memoranda\n",
      "Extracted: Neighbourhood Policing Guarantee performance framework\n",
      "Extracted: EM on UK/EU TCA Specialised Committee decision (COM(2025)48)\n",
      "Extracted: Programme of flood and coastal erosion risk management (FCERM) schemes\n",
      "Extracted: Agenda of the 14th meeting of the Withdrawal Agreement Joint Committee, 29 April 2025\n",
      "Extracted: Annual report on devolution 2023 to 2024\n",
      "Extracted: Terrorism (Protection of Premises) Act 2025: factsheets\n",
      "Extracted: Mpox control and elimination: UK strategy 2025 to 2026\n",
      "Extracted: The Pall Mall Process Code of Practice for States\n",
      "Extracted: Cyber governance mapping\n",
      "Extracted: DSIT cyber security newsletter - April 2025\n",
      "Extracted: Direction under regulation 2(2) of the Delivery of Tax Information through Software (Ancillary Metadata) Regulations 2019 (S.I. 2019/360)\n",
      "Extracted: Governance of Engineering Biology: government response to recommendations made by the Regulatory Horizons Council\n",
      "Extracted: Clean Power 2030 Action Plan\n",
      "Extracted: Transforming the criminal justice response to domestic abuse\n",
      "Extracted: London Sudan Conference 2025: co-chairs' statement\n",
      "Extracted: Steel Industry (Special Measures) Bill\n",
      "Extracted: HMCTS Vulnerability Action Plan\n",
      "Total results so far: 19\n",
      "Found 19 policies\n",
      "Saved policies data to policy_data/all_policies.csv\n",
      "Category structure saved to policy_data/category_structure.json\n",
      "\n",
      "Category Summary:\n",
      "========================================\n",
      "Crime, justice and law: 6 policies\n",
      "  - Criminal justice reform: 2 policies\n",
      "  - Policing: 1 policies\n",
      "  - Counter-terrorism: 1 policies\n",
      "  - Domestic abuse: 1 policies\n",
      "  - Courts, sentencing and tribunals: 1 policies\n",
      "Government: 6 policies\n",
      "  - Europe: 1 policies\n",
      "  - Brexit: 1 policies\n",
      "  - Cyber security: 3 policies\n",
      "  - Government efficiency, transparency and accountability: 1 policies\n",
      "Environment: 1 policies\n",
      "  - River maintenance, flooding and coastal erosion: 1 policies\n",
      "Business and industry: 4 policies\n",
      "  - UK economy: 1 policies\n",
      "  - Running a business: 1 policies\n",
      "  - Science and innovation: 1 policies\n",
      "  - Manufacturing: 1 policies\n",
      "Health and social care: 1 policies\n",
      "  - Public health: 1 policies\n",
      "International: 1 policies\n",
      "  - Foreign affairs: 1 policies\n",
      "Downloading attachments for 19 policies...\n",
      "Processing: Crime and Policing Bill 2025: Delegated powers supplementary memoranda\n",
      "Downloading: Supplementary_DP_memo_-_YDOs.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Criminal justice reform/Crime and Policing Bill 2025 Delegated powers supplementary memoranda/Supplementary_DP_memo_-_YDOs.pdf\n",
      "Downloading: Supplementary_DP_memo_-_YDOs.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Criminal justice reform/Crime and Policing Bill 2025 Delegated powers supplementary memoranda/Supplementary_DP_memo_-_YDOs.pdf\n",
      "Downloading: Supplementary_DP_memo_-_YDOs.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Criminal justice reform/Crime and Policing Bill 2025 Delegated powers supplementary memoranda/Supplementary_DP_memo_-_YDOs.pdf\n",
      "Downloading: Supplementary_DP_memo_-_YDOs.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Criminal justice reform/Crime and Policing Bill 2025 Delegated powers supplementary memoranda/Supplementary_DP_memo_-_YDOs.pdf\n",
      "Processing: Crime and Policing Bill 2025: ECHR supplementary memoranda\n",
      "Downloading: First_Supplementary_ECHR_Memorandum_-_YDOs_-_FINAL_.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Criminal justice reform/Crime and Policing Bill 2025 ECHR supplementary memoranda/First_Supplementary_ECHR_Memorandum_-_YDOs_-_FINAL_.pdf\n",
      "Downloading: First_Supplementary_ECHR_Memorandum_-_YDOs_-_FINAL_.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Criminal justice reform/Crime and Policing Bill 2025 ECHR supplementary memoranda/First_Supplementary_ECHR_Memorandum_-_YDOs_-_FINAL_.pdf\n",
      "Downloading: First_Supplementary_ECHR_Memorandum_-_YDOs_-_FINAL_.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Criminal justice reform/Crime and Policing Bill 2025 ECHR supplementary memoranda/First_Supplementary_ECHR_Memorandum_-_YDOs_-_FINAL_.pdf\n",
      "Downloading: First_Supplementary_ECHR_Memorandum_-_YDOs_-_FINAL_.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Criminal justice reform/Crime and Policing Bill 2025 ECHR supplementary memoranda/First_Supplementary_ECHR_Memorandum_-_YDOs_-_FINAL_.pdf\n",
      "Processing: Neighbourhood Policing Guarantee performance framework\n",
      "Downloading: Neighbourhood+Policing+Guarantee+Performance+Framework+-+version+for+publication.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Policing/Neighbourhood Policing Guarantee performance framework/Neighbourhood+Policing+Guarantee+Performance+Framework+-+version+for+publication.pdf\n",
      "Downloading: Neighbourhood+Policing+Guarantee+Performance+Framework+-+version+for+publication.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Policing/Neighbourhood Policing Guarantee performance framework/Neighbourhood+Policing+Guarantee+Performance+Framework+-+version+for+publication.pdf\n",
      "Downloading: Neighbourhood+Policing+Guarantee+Performance+Framework+-+version+for+publication.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Policing/Neighbourhood Policing Guarantee performance framework/Neighbourhood+Policing+Guarantee+Performance+Framework+-+version+for+publication.pdf\n",
      "Downloading: Neighbourhood+Policing+Guarantee+Performance+Framework+-+version+for+publication.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Policing/Neighbourhood Policing Guarantee performance framework/Neighbourhood+Policing+Guarantee+Performance+Framework+-+version+for+publication.pdf\n",
      "Processing: EM on UK/EU TCA Specialised Committee decision (COM(2025)48)\n",
      "Downloading: XST_signed_EM_on_UK-EU_Trade_and_Cooperation_Agreement_governance_document_COM_2025_48__1_.pdf\n",
      "Saved to: policy_data/Government/Europe/EM on UKEU TCA Specialised Committee decision (COM(2025)48)/XST_signed_EM_on_UK-EU_Trade_and_Cooperation_Agreement_governance_document_COM_2025_48__1_.pdf\n",
      "Downloading: XST_signed_EM_on_UK-EU_Trade_and_Cooperation_Agreement_governance_document_COM_2025_48__1_.pdf\n",
      "Saved to: policy_data/Government/Europe/EM on UKEU TCA Specialised Committee decision (COM(2025)48)/XST_signed_EM_on_UK-EU_Trade_and_Cooperation_Agreement_governance_document_COM_2025_48__1_.pdf\n",
      "Downloading: XST_signed_EM_on_UK-EU_Trade_and_Cooperation_Agreement_governance_document_COM_2025_48__1_.pdf\n",
      "Saved to: policy_data/Government/Europe/EM on UKEU TCA Specialised Committee decision (COM(2025)48)/XST_signed_EM_on_UK-EU_Trade_and_Cooperation_Agreement_governance_document_COM_2025_48__1_.pdf\n",
      "Downloading: XST_signed_EM_on_UK-EU_Trade_and_Cooperation_Agreement_governance_document_COM_2025_48__1_.pdf\n",
      "Saved to: policy_data/Government/Europe/EM on UKEU TCA Specialised Committee decision (COM(2025)48)/XST_signed_EM_on_UK-EU_Trade_and_Cooperation_Agreement_governance_document_COM_2025_48__1_.pdf\n",
      "Processing: Programme of flood and coastal erosion risk management (FCERM) schemes\n",
      "Downloading: List_of_schemes_invested_in_between_April_2025_and_March_2026.xlsx\n",
      "Saved to: policy_data/Environment/River maintenance, flooding and coastal erosion/Programme of flood and coastal erosion risk management (FCERM) schemes/List_of_schemes_invested_in_between_April_2025_and_March_2026.xlsx\n",
      "Downloading: List_of_schemes_invested_in_between_April_2025_and_March_2026.xlsx\n",
      "Saved to: policy_data/Environment/River maintenance, flooding and coastal erosion/Programme of flood and coastal erosion risk management (FCERM) schemes/List_of_schemes_invested_in_between_April_2025_and_March_2026.xlsx\n",
      "Downloading: List_of_schemes_invested_in_between_April_2025_and_March_2026.xlsx\n",
      "Saved to: policy_data/Environment/River maintenance, flooding and coastal erosion/Programme of flood and coastal erosion risk management (FCERM) schemes/List_of_schemes_invested_in_between_April_2025_and_March_2026.xlsx\n",
      "Downloading: List_of_schemes_invested_in_between_April_2025_and_March_2026.xlsx\n",
      "Saved to: policy_data/Environment/River maintenance, flooding and coastal erosion/Programme of flood and coastal erosion risk management (FCERM) schemes/List_of_schemes_invested_in_between_April_2025_and_March_2026.xlsx\n",
      "Processing: Agenda of the 14th meeting of the Withdrawal Agreement Joint Committee, 29 April 2025\n",
      "Processing: Annual report on devolution 2023 to 2024\n",
      "Downloading: Annual_Report_on_Devolution_2023-24.pdf\n",
      "Saved to: policy_data/Business and industry/UK economy/Annual report on devolution 2023 to 2024/Annual_Report_on_Devolution_2023-24.pdf\n",
      "Downloading: Annual_Report_on_Devolution_2023-24.pdf\n",
      "Saved to: policy_data/Business and industry/UK economy/Annual report on devolution 2023 to 2024/Annual_Report_on_Devolution_2023-24.pdf\n",
      "Downloading: Annual_Report_on_Devolution_2023-24.pdf\n",
      "Saved to: policy_data/Business and industry/UK economy/Annual report on devolution 2023 to 2024/Annual_Report_on_Devolution_2023-24.pdf\n",
      "Downloading: Annual_Report_on_Devolution_2023-24.pdf\n",
      "Saved to: policy_data/Business and industry/UK economy/Annual report on devolution 2023 to 2024/Annual_Report_on_Devolution_2023-24.pdf\n",
      "Processing: Terrorism (Protection of Premises) Act 2025: factsheets\n",
      "Processing: Mpox control and elimination: UK strategy 2025 to 2026\n",
      "Processing: The Pall Mall Process Code of Practice for States\n",
      "Downloading: Pall-Mall-Process-Code-of-Practice-for-States.pdf\n",
      "Saved to: policy_data/Government/Cyber security/The Pall Mall Process Code of Practice for States/Pall-Mall-Process-Code-of-Practice-for-States.pdf\n",
      "Downloading: Pall-Mall-Process-Code-of-Practice-for-States.pdf\n",
      "Saved to: policy_data/Government/Cyber security/The Pall Mall Process Code of Practice for States/Pall-Mall-Process-Code-of-Practice-for-States.pdf\n",
      "Downloading: Pall-Mall-Process-Code-of-Practice-for-States.pdf\n",
      "Saved to: policy_data/Government/Cyber security/The Pall Mall Process Code of Practice for States/Pall-Mall-Process-Code-of-Practice-for-States.pdf\n",
      "Downloading: Pall-Mall-Process-Code-of-Practice-for-States.pdf\n",
      "Saved to: policy_data/Government/Cyber security/The Pall Mall Process Code of Practice for States/Pall-Mall-Process-Code-of-Practice-for-States.pdf\n",
      "Processing: Cyber governance mapping\n",
      "Processing: DSIT cyber security newsletter - April 2025\n",
      "Processing: Direction under regulation 2(2) of the Delivery of Tax Information through Software (Ancillary Metadata) Regulations 2019 (S.I. 2019/360)\n",
      "Processing: Governance of Engineering Biology: government response to recommendations made by the Regulatory Horizons Council\n",
      "Processing: Clean Power 2030 Action Plan\n",
      "Downloading: clean-power-2030-action-plan-main-report.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-main-report.pdf\n",
      "Downloading: clean-power-2030-action-plan-main-report.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-main-report.pdf\n",
      "Downloading: clean-power-2030-action-plan-main-report.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-main-report.pdf\n",
      "Downloading: clean-power-2030-action-plan-main-report.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-main-report.pdf\n",
      "Downloading: clean-power-2030-action-plan-technical-annex.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-technical-annex.pdf\n",
      "Downloading: clean-power-2030-action-plan-technical-annex.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-technical-annex.pdf\n",
      "Downloading: clean-power-2030-action-plan-technical-annex.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-technical-annex.pdf\n",
      "Downloading: clean-power-2030-action-plan-technical-annex.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-technical-annex.pdf\n",
      "Downloading: clean-power-2030-action-plan-connections-reform-annex-update.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-connections-reform-annex-update.pdf\n",
      "Downloading: clean-power-2030-action-plan-connections-reform-annex-update.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-connections-reform-annex-update.pdf\n",
      "Downloading: clean-power-2030-action-plan-connections-reform-annex-update.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-connections-reform-annex-update.pdf\n",
      "Downloading: clean-power-2030-action-plan-connections-reform-annex-update.pdf\n",
      "Saved to: policy_data/Government/Government efficiency, transparency and accountability/Clean Power 2030 Action Plan/clean-power-2030-action-plan-connections-reform-annex-update.pdf\n",
      "Processing: Transforming the criminal justice response to domestic abuse\n",
      "Downloading: E03263274_Shifting+the+scales_ACCESSIBLE.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_ACCESSIBLE.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_ACCESSIBLE.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_ACCESSIBLE.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_ACCESSIBLE.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_ACCESSIBLE.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_ACCESSIBLE.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_ACCESSIBLE.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_LP_ELAY.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_LP_ELAY.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_LP_ELAY.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_LP_ELAY.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_LP_ELAY.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_LP_ELAY.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_LP_ELAY.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_LP_ELAY.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_WELSH_Web+Accessible.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_WELSH_Web+Accessible.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_WELSH_Web+Accessible.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_WELSH_Web+Accessible.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_WELSH_Web+Accessible.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_WELSH_Web+Accessible.pdf\n",
      "Downloading: E03263274_Shifting+the+scales_WELSH_Web+Accessible.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Domestic abuse/Transforming the criminal justice response to domestic abuse/E03263274_Shifting+the+scales_WELSH_Web+Accessible.pdf\n",
      "Processing: London Sudan Conference 2025: co-chairs' statement\n",
      "Processing: Steel Industry (Special Measures) Bill\n",
      "Downloading: draft_steel_industry_special_measures_bill.pdf\n",
      "Saved to: policy_data/Business and industry/Manufacturing/Steel Industry (Special Measures) Bill/draft_steel_industry_special_measures_bill.pdf\n",
      "Downloading: draft_steel_industry_special_measures_bill.pdf\n",
      "Saved to: policy_data/Business and industry/Manufacturing/Steel Industry (Special Measures) Bill/draft_steel_industry_special_measures_bill.pdf\n",
      "Downloading: draft_steel_industry_special_measures_bill.pdf\n",
      "Saved to: policy_data/Business and industry/Manufacturing/Steel Industry (Special Measures) Bill/draft_steel_industry_special_measures_bill.pdf\n",
      "Downloading: draft_steel_industry_special_measures_bill.pdf\n",
      "Saved to: policy_data/Business and industry/Manufacturing/Steel Industry (Special Measures) Bill/draft_steel_industry_special_measures_bill.pdf\n",
      "Processing: HMCTS Vulnerability Action Plan\n",
      "Downloading: ISL265_24_ER_Vulnerable_User_Plan_Oct_2024_Final_low_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL265_24_ER_Vulnerable_User_Plan_Oct_2024_Final_low_res.pdf\n",
      "Downloading: ISL265_24_ER_Vulnerable_User_Plan_Oct_2024_Final_low_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL265_24_ER_Vulnerable_User_Plan_Oct_2024_Final_low_res.pdf\n",
      "Downloading: ISL265_24_ER_Vulnerable_User_Plan_Oct_2024_Final_low_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL265_24_ER_Vulnerable_User_Plan_Oct_2024_Final_low_res.pdf\n",
      "Downloading: ISL265_24_ER_Vulnerable_User_Plan_Oct_2024_Final_low_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL265_24_ER_Vulnerable_User_Plan_Oct_2024_Final_low_res.pdf\n",
      "Downloading: ISL134_24_ER_Vulnerable_User_Plan_April_2024_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL134_24_ER_Vulnerable_User_Plan_April_2024_Final_high_res.pdf\n",
      "Downloading: ISL134_24_ER_Vulnerable_User_Plan_April_2024_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL134_24_ER_Vulnerable_User_Plan_April_2024_Final_high_res.pdf\n",
      "Downloading: ISL134_24_ER_Vulnerable_User_Plan_April_2024_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL134_24_ER_Vulnerable_User_Plan_April_2024_Final_high_res.pdf\n",
      "Downloading: ISL134_24_ER_Vulnerable_User_Plan_April_2024_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL134_24_ER_Vulnerable_User_Plan_April_2024_Final_high_res.pdf\n",
      "Downloading: ISL209_23__ER_Vulnerable_User_plan_October_2023_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL209_23__ER_Vulnerable_User_plan_October_2023_Final_high_res.pdf\n",
      "Downloading: ISL209_23__ER_Vulnerable_User_plan_October_2023_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL209_23__ER_Vulnerable_User_plan_October_2023_Final_high_res.pdf\n",
      "Downloading: ISL209_23__ER_Vulnerable_User_plan_October_2023_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL209_23__ER_Vulnerable_User_plan_October_2023_Final_high_res.pdf\n",
      "Downloading: ISL209_23__ER_Vulnerable_User_plan_October_2023_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL209_23__ER_Vulnerable_User_plan_October_2023_Final_high_res.pdf\n",
      "Downloading: ISL115_23__ER_Vulnerable_User_plan_April_23_NEW_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL115_23__ER_Vulnerable_User_plan_April_23_NEW_Final_high_res.pdf\n",
      "Downloading: ISL115_23__ER_Vulnerable_User_plan_April_23_NEW_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL115_23__ER_Vulnerable_User_plan_April_23_NEW_Final_high_res.pdf\n",
      "Downloading: ISL115_23__ER_Vulnerable_User_plan_April_23_NEW_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL115_23__ER_Vulnerable_User_plan_April_23_NEW_Final_high_res.pdf\n",
      "Downloading: ISL115_23__ER_Vulnerable_User_plan_April_23_NEW_Final_high_res.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL115_23__ER_Vulnerable_User_plan_April_23_NEW_Final_high_res.pdf\n",
      "Downloading: ISL296_22_ER_Vulnerable_User_plan_Oct_22_Final_web_acc.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL296_22_ER_Vulnerable_User_plan_Oct_22_Final_web_acc.pdf\n",
      "Downloading: ISL296_22_ER_Vulnerable_User_plan_Oct_22_Final_web_acc.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL296_22_ER_Vulnerable_User_plan_Oct_22_Final_web_acc.pdf\n",
      "Downloading: ISL296_22_ER_Vulnerable_User_plan_Oct_22_Final_web_acc.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL296_22_ER_Vulnerable_User_plan_Oct_22_Final_web_acc.pdf\n",
      "Downloading: ISL296_22_ER_Vulnerable_User_plan_Oct_22_Final_web_acc.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISL296_22_ER_Vulnerable_User_plan_Oct_22_Final_web_acc.pdf\n",
      "Downloading: ISl155_22_ER_Vulnerable_User_plan_Final_web_acc.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISl155_22_ER_Vulnerable_User_plan_Final_web_acc.pdf\n",
      "Downloading: ISl155_22_ER_Vulnerable_User_plan_Final_web_acc.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISl155_22_ER_Vulnerable_User_plan_Final_web_acc.pdf\n",
      "Downloading: ISl155_22_ER_Vulnerable_User_plan_Final_web_acc.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISl155_22_ER_Vulnerable_User_plan_Final_web_acc.pdf\n",
      "Downloading: ISl155_22_ER_Vulnerable_User_plan_Final_web_acc.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/ISl155_22_ER_Vulnerable_User_plan_Final_web_acc.pdf\n",
      "Downloading: Vulnerability_Action_plan_2021_v3.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/Vulnerability_Action_plan_2021_v3.pdf\n",
      "Downloading: Vulnerability_Action_plan_2021_v3.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/Vulnerability_Action_plan_2021_v3.pdf\n",
      "Downloading: Vulnerability_Action_plan_2021_v3.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/Vulnerability_Action_plan_2021_v3.pdf\n",
      "Downloading: Vulnerability_Action_plan_2021_v3.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/Vulnerability_Action_plan_2021_v3.pdf\n",
      "Downloading: HMCTS_Vulnerability_Action_Plan.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/HMCTS_Vulnerability_Action_Plan.pdf\n",
      "Downloading: HMCTS_Vulnerability_Action_Plan.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/HMCTS_Vulnerability_Action_Plan.pdf\n",
      "Downloading: HMCTS_Vulnerability_Action_Plan.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/HMCTS_Vulnerability_Action_Plan.pdf\n",
      "Downloading: HMCTS_Vulnerability_Action_Plan.pdf\n",
      "Saved to: policy_data/Crime, justice and law/Courts, sentencing and tribunals/HMCTS Vulnerability Action Plan/HMCTS_Vulnerability_Action_Plan.pdf\n",
      "Total attachments downloaded: 88\n",
      "\n",
      "Scraping Summary:\n",
      "Total policies found: 19\n",
      "Total categories: 6\n",
      "Total attachments downloaded: 88\n",
      "All data has been organized in the 'policy_data' directory\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the scraper\"\"\"\n",
    "    # Create scraper instance\n",
    "    scraper = GovUKPolicyScraper(base_dir=\"policy_data\")\n",
    "    \n",
    "    # Step 1: Search and extract policies\n",
    "    policies = scraper.search_policies(\n",
    "        search_term=None,  # Set a search term or None for all policies\n",
    "        page_limit=1,      # Number of pages to scrape\n",
    "        exclude_types=[\"consultation\", \"open consultation\", \"closed consultation\"]\n",
    "    )\n",
    "    \n",
    "    # Step 2: Categorize the policies\n",
    "    categories = scraper.categorize_policies(policies)\n",
    "    \n",
    "    # Step 3: Download and organize attachments\n",
    "    download_count = scraper.download_policy_attachments(policies)\n",
    "    \n",
    "    print(\"\\nScraping Summary:\")\n",
    "    print(f\"Total policies found: {len(policies)}\")\n",
    "    print(f\"Total categories: {len(categories)}\")\n",
    "    print(f\"Total attachments downloaded: {download_count}\")\n",
    "    print(f\"All data has been organized in the '{scraper.base_dir}' directory\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
